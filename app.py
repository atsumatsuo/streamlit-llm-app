import os
from pathlib import Path

import streamlit as st
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import importlib.metadata as md  # ãƒ‡ãƒãƒƒã‚°ç”¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨ç¤ºã«ä½¿ã†

# --- .env ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç”¨ã€‚Cloudã§ã¯ st.secrets ã‚’ä½¿ã†ï¼‰ ---
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

# --- APIã‚­ãƒ¼å–å¾—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«=.env / æœ¬ç•ª=Secrets ã®ä¸¡å¯¾å¿œï¼‰ ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")

# --- ä¾¿åˆ©ãƒ‡ãƒãƒƒã‚°ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¡¨ç¤ºï¼‰ ---
def show_debug():
    st.sidebar.header("ğŸ›  Debug")

    def ver(name: str):
        try:
            return md.version(name)
        except Exception:
            return "(not installed)"

    st.sidebar.write({
        "streamlit": ver("streamlit"),
        "openai": ver("openai"),
        "langchain": ver("langchain"),
        "langchain-openai": ver("langchain-openai"),
        "httpx": ver("httpx"),
    })

    keys = [
        "HTTP_PROXY","HTTPS_PROXY","ALL_PROXY",
        "http_proxy","https_proxy","all_proxy",
        "OPENAI_PROXY","PROXIES","proxies",
    ]
    st.sidebar.subheader("Proxy envs (set only)")
    st.sidebar.json({k: os.environ.get(k) for k in keys if os.environ.get(k)})

# ï¼ˆå¿…è¦ãªã¨ãã ã‘ãƒã‚§ãƒƒã‚¯ONï¼‰
if st.sidebar.checkbox("Show debug info", value=False):
    show_debug()

# --- ã“ã“ã‹ã‚‰ã‚¢ãƒ—ãƒªæœ¬ä½“ ---
st.title("å°‚é–€å®¶AIç›¸è«‡ã‚¢ãƒ—ãƒª")

# APIã‚­ãƒ¼ãŒç„¡ã‘ã‚Œã°æ­¢ã‚ã‚‹ï¼ˆCloud/ãƒ­ãƒ¼ã‚«ãƒ«å…±é€šï¼‰
if not OPENAI_API_KEY:
    st.error("OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚.env ã‹ Streamlit Secrets ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
EXPERT_SYSTEM_MESSAGES = {
    "å¥åº·": "ã‚ãªãŸã¯å¥åº·åˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥åº·ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚",
    "ãŠé‡‘": "ã‚ãªãŸã¯é‡‘èåˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãŠé‡‘ã‚„æŠ•è³‡ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚",
    "ã‚­ãƒ£ãƒªã‚¢": "ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»•äº‹ã‚„ã‚­ãƒ£ãƒªã‚¢ã«é–¢ã™ã‚‹ç›¸è«‡ã«è¦ªèº«ã«ç­”ãˆã¦ãã ã•ã„ã€‚",
    "æ•™è‚²": "ã‚ãªãŸã¯æ•™è‚²åˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’ã‚„æ•™è‚²ã«é–¢ã™ã‚‹è³ªå•ã«åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚",
}

def get_llm_response(input_text: str, expert_type: str) -> str:
    system_message = EXPERT_SYSTEM_MESSAGES.get(expert_type, "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
    # â˜… v1ç³»ã«åˆã‚ã›ãŸæ­£ã—ã„åˆæœŸåŒ–ï¼šapi_key ã ã‘æ¸¡ã™ï¼ˆclient/create ã¯ä½¿ã‚ãªã„ï¼‰
    chat = ChatOpenAI(
        model="gpt-3.5-turbo",   # å¿…è¦ãªã‚‰ "gpt-4o-mini" ãªã©ã«å¤‰æ›´OK
        temperature=0.7,
        api_key=OPENAI_API_KEY,
    )
    messages = [SystemMessage(content=system_message), HumanMessage(content=input_text)]
    response = chat.invoke(messages)
    return response.content

expert_type = st.radio("ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„", list(EXPERT_SYSTEM_MESSAGES.keys()))
input_text = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("é€ä¿¡"):
    if input_text.strip():
        try:
            with st.spinner("AIãŒå›ç­”ä¸­..."):
                answer = get_llm_response(input_text, expert_type)
            st.markdown("### å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"AIã®å›ç­”å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
