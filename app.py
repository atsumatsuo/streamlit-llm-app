import os
from pathlib import Path
import streamlit as st
from dotenv import load_dotenv

def show_debug():
    import importlib.metadata as md  # â† é–¢æ•°å†…ã§ç¢ºå®Ÿã«å®šç¾©
    st.sidebar.header("ğŸ›  Debug")

    def ver(name: str):
        try:
            return md.version(name)
        except Exception:
            return "(not installed)"

    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨ç¤º
    st.sidebar.write({
        "streamlit": ver("streamlit"),
        "openai": ver("openai"),
        "langchain": ver("langchain"),
        "langchain-openai": ver("langchain-openai"),
        "httpx": ver("httpx"),
    })

    # ãƒ—ãƒ­ã‚­ã‚·ç³»ç’°å¢ƒå¤‰æ•°ã®æœ‰ç„¡ã‚’è¡¨ç¤ºï¼ˆå€¤ãŒã‚ã‚‹ã‚‚ã®ã ã‘ï¼‰
    keys = [
        "HTTP_PROXY","HTTPS_PROXY","ALL_PROXY",
        "http_proxy","https_proxy","all_proxy",
        "OPENAI_PROXY","PROXIES","proxies"
    ]
    st.sidebar.subheader("Proxy envs (set only)")
    st.sidebar.json({k: os.environ.get(k) for k in keys if os.environ.get(k)})


# ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§ON/OFFã§ãã‚‹ã‚ˆã†ã«
if st.sidebar.checkbox("Show debug info", value=True):
    show_debug()

# --- â‘  .env èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç”¨ï¼‰ ---
load_dotenv(dotenv_path=Path(__file__).parent / ".env")

# --- â‘¡ ãƒ—ãƒ­ã‚­ã‚·ç’°å¢ƒå¤‰æ•°ã‚’ç„¡åŠ¹åŒ–ï¼ˆä¸è¦ãªã‚‰å…¨éƒ¨ã‚«ãƒƒãƒˆï¼‰ ---
for k in ["HTTP_PROXY","HTTPS_PROXY","ALL_PROXY","http_proxy","https_proxy","all_proxy","OPENAI_PROXY","PROXIES","proxies"]:
    os.environ.pop(k, None)

# --- â‘¢ APIã‚­ãƒ¼å–å¾—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«=.env / æœ¬ç•ª=Secrets ã®ä¸¡å¯¾å¿œï¼‰ ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ï¼ˆ.env ã‹ Secrets ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼‰")
    st.stop()

from openai import OpenAI
import httpx
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

import importlib.metadata as md

# --- â‘£ OpenAIå…¬å¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è‡ªåˆ†ã§ä½œã£ã¦ ChatOpenAI ã«æ¸¡ã™ ---
# ãƒ—ãƒ­ã‚­ã‚·ãŒä¸è¦ãªã‚‰ãã®ã¾ã¾
oai = OpenAI(api_key=OPENAI_API_KEY)

# ï¼ˆç¤¾å†…ãƒ—ãƒ­ã‚­ã‚·ãŒå¿…é ˆã®äººã ã‘ï¼‰
# http_client = httpx.Client(proxies="http://proxy.example.com:8080")
# oai = OpenAI(api_key=OPENAI_API_KEY, http_client=http_client)

EXPERT_SYSTEM_MESSAGES = {
    "å¥åº·": "ã‚ãªãŸã¯å¥åº·åˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¥åº·ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚",
    "ãŠé‡‘": "ã‚ãªãŸã¯é‡‘èåˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãŠé‡‘ã‚„æŠ•è³‡ã«é–¢ã™ã‚‹è³ªå•ã«å°‚é–€çš„ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚",
    "ã‚­ãƒ£ãƒªã‚¢": "ã‚ãªãŸã¯ã‚­ãƒ£ãƒªã‚¢ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä»•äº‹ã‚„ã‚­ãƒ£ãƒªã‚¢ã«é–¢ã™ã‚‹ç›¸è«‡ã«è¦ªèº«ã«ç­”ãˆã¦ãã ã•ã„ã€‚",
    "æ•™è‚²": "ã‚ãªãŸã¯æ•™è‚²åˆ†é‡ã®å°‚é–€å®¶ã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å­¦ç¿’ã‚„æ•™è‚²ã«é–¢ã™ã‚‹è³ªå•ã«åˆ†ã‹ã‚Šã‚„ã™ãç­”ãˆã¦ãã ã•ã„ã€‚"
}

def get_llm_response(input_text: str, expert_type: str) -> str:
    system_message = EXPERT_SYSTEM_MESSAGES.get(expert_type, "ã‚ãªãŸã¯å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
    chat = ChatOpenAI(
        model="gpt-3.5-turbo",   # ä¾‹ï¼šè»½ã‚ã®ãƒ¢ãƒ‡ãƒ«ã€‚å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´OK
        temperature=0.7,
        client=oai               # â† ã“ã“ãŒè‚ã€‚è‡ªå‰ã® OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¸¡ã™
    )
    messages = [SystemMessage(content=system_message), HumanMessage(content=input_text)]
    resp = chat.invoke(messages)
    return resp.content

st.title("å°‚é–€å®¶AIç›¸è«‡ã‚¢ãƒ—ãƒª")

expert_type = st.radio("ç›¸è«‡ã—ãŸã„å°‚é–€å®¶ã‚’é¸ã‚“ã§ãã ã•ã„", list(EXPERT_SYSTEM_MESSAGES.keys()))
input_text = st.text_area("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("é€ä¿¡"):
    if input_text.strip():
        try:
            with st.spinner("AIãŒå›ç­”ä¸­..."):
                answer = get_llm_response(input_text, expert_type)
            st.markdown("### å›ç­”")
            st.write(answer)
        except Exception as e:
            st.error(f"AIã®å›ç­”å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    else:
        st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
